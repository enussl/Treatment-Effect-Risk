rm(list=ls())
# GENERATE DATA
n <- 100 #number of observations
p <- 50 #number of parameters (excluding intercept)
set.seed(0)
tmp <- rnorm(n*p, mean = 0, sd = 1) #generate covariates
X <- matrix(data = tmp, nrow = n, ncol = p)
set.seed(0)
beta <- c(1,sample(c(0,1), p,T,c(0.9,0.1))) #generate beta
y <- beta[1] + X%*%beta[2:51]+rnorm(n, mean = 0, sd = 1)
sse <- function(v) #function to calculate sum of squared errors
{sum((beta-v)^2)}
#FIT CROSS-VALIDATED LASSO
set.seed(0)
fit <- cv.glmnet(x = X,y = y,alpha = 1, nfolds = 10)
?coef.glmnet
lambda_a <- fit$lambda.min  #find lambda with minimum mean cross-validated error
beta_a <- coef.glmnet(object = fit, s = lambda_a)  #extract coefficients
set.seed(0)
fit <- cv.glmnet(x = X,y = y,alpha = 1, nfolds = 10)
lambda_a <- fit$lambda.min  #find lambda with minimum mean cross-validated error
beta_a <- coef.glmnet(object = fit, s = lambda_a)  #extract coefficients
lambda_b <- fit$lambda.1se #find lambda according to 1-standard-error rule
beta_b <- coef.glmnet(object = fit, s = lambda_b)   #extract coefficients
round(lambda_b,4)
sse_a = sse(beta_a)
sse_b = sse(beta_b)
round(sse_b,4)
View(beta_a)
View(beta_b)
beta_b@i
beta_b@Dimnames
beta_b@p
View(beta_a)
beta_b@i
length(beta_b@i)
sigmoid = function(x) exp(x)/(1+exp(x))
sigmoid(14)
sigmoid(2-7*sigmoid(14)+6*sigmoid(25))
round(sigmoid(2-7*sigmoid(14)+6*sigmoid(25)),4)
?relu
relu = function(x) ifelse(x>=0, x, 0)
round(relu(2-7*relu(14)+6*relu(25)),4)
rm(list=ls())
data(LifeCycleSavings)
library(mgcv)
str(LifeCycleSavings)
gam(sr ~ ., data = LifeCycleSavings)
gam(sr ~ s(pop15)+s(pop75)+s(dpi)+s(ddpi), data = LifeCycleSavings)
fit = gam(sr ~ s(pop15)+s(pop75)+s(dpi)+s(ddpi), data = LifeCycleSavings)
summary(fit)
round(0.68403,4)
plot(fit)
?rpart
fit1 = rpart(sr ~ ., data = LifeCycleSavings)
library(rpart)
fit1 = rpart(sr ~ ., data = LifeCycleSavings)
rpart.plot(fit1)
prp(fit1)
library(rpart.plot)
prp(fit1)
rm(list=ls())
# Data:
x <- c(-1,1,100)
# Initialize estimate
estimate <- 0
set.seed(0)
?sample
# Data:
x <- c(-1,1,100)
# Initialize estimate
estimate <- 0
set.seed(0)
for(i in 1:20)
{
# Step 1: Generate a bootstrap sample
x_boot <- sample(x, size = 3, replace = T)
# Step 2: compute estimator on bootstrap sample
g_hat <- var(x_boot)
# Step 3: aggregate the bootstrap estimates
estimate <- estimate + g_hat
}
length(1:20)
round(estimate/20,4)
?apply
?ksmooth
?stem
?lokerns
install.packages("lokern")
?lokerns
?lokerns
library(lokern)
?lokerns
?trace
?smooth.spline
?boot
?rgamma
?fitdistr
install.packages("fitdistrplus")
library(fistdistrplu)
library(fistdistrplus)
library(fitdistrplus)
?fitdist
?prp
cv.eln$???
lifeexp <- read.table(url, sep="\t", header=T, row.names=1)
url <- "https://raw.githubusercontent.com/jawj/coffeestats/master/lifeexp.dat"
lifeexp <- read.table(url, sep="\t", header=T, row.names=1)
View(lifeexp)
log(2)
?lokerns
?smooth.spline
sigmoid
?sigmoid
library(MASS)
library(PerformanceAnalytics)
sigma = matrix(c(1, 0.7, 0.7, 1), ncol = 2, nrow = 2)
data = mvrnorm(n = 100000, mu = c(1,2), Sigma = sigma)
cvar.x = PerformanceAnalytics::ES(data[,1])
hist(data[,1])
quantile(data[,1], 0.05)
sigma = matrix(c(1, 0.7, 0.7, 1), ncol = 2, nrow = 2)
data = mvrnorm(n = 100000, mu = c(0,0), Sigma = sigma)
cvar.x = PerformanceAnalytics::ES(data[,1])
View(data)
hist(data[,1])
data = data.frame(mvrnorm(n = 100000, mu = c(0,0), Sigma = sigma))
View(data)
cvar.x = data %>%
select(V1) %>%
arrange(V1)
library(dplyr)
cvar.x = data %>%
select(V1) %>%
arrange(V1)
cvar.x = data %>%
select(X1) %>%
arrange(X1)
View(cvar.x)
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05)))
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05))) %>%
filter(X1 <= worst_5) %>%
select(X1) %>%
mutate(cvar = mean(X1))
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05))) %>%
filter(X1 <= worst_5) %>%
select(X1) %>%
mutate(cvar = mean(X1)) %>%
slice(1)
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05))) %>%
filter(X1 <= worst_5) %>%
select(X1) %>%
mutate(cvar.1 = mean(X1)) %>%
slice(1)
cvar.y = data %>%
select(X2) %>%
arrange(X2) %>%
mutate(worst_5 = as.numeric(quantile(X2, 0.05))) %>%
filter(X2) %>%
select(X2) %>%
mutate(cvar.2 = mean(X2)) %>%
slice(1)
cvar.xy = data %>%
mutate(X1_X2 = X1+X2) %>%
mutate(worst_5 = as.numeric(quantile(X1_X2, 0.05))) %>%
filter(X1_X2) %>%
select(X1_X2) %>%
mutate(cvar.2 = mean(X1_X2)) %>%
slice(1)
cvar.y = data %>%
select(X2) %>%
arrange(X2) %>%
mutate(worst_5 = as.numeric(quantile(X2, 0.05))) %>%
filter(X2 <= worst_5) %>%
select(X2) %>%
mutate(cvar.2 = mean(X2)) %>%
slice(1)
View(cvar.y)
cvar.xy = data %>%
mutate(X1_X2 = X1+X2) %>%
mutate(worst_5 = as.numeric(quantile(X1_X2, 0.05))) %>%
filter(X1_X2 <= worst_5) %>%
select(X1_X2) %>%
mutate(cvar.2 = mean(X1_X2)) %>%
slice(1)
View(cvar.xy)
View(cvar.xy)
cvar.xy$X1_X2-cvar.x$X1-cvar.y$X2
cvar.xy$X1_X2+cvar.x$X1+cvar.y$X2
cvar.xy$X1_X2-cvar.x$X1-cvar.y$X2
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05))) %>%
filter(X1 <= worst_5) %>%
select(X1) %>%
mutate(cvar.1 = mean(X1)) %>%
slice(1)
cvar.y = data %>%
select(X2) %>%
arrange(X2) %>%
mutate(worst_5 = as.numeric(quantile(X2, 0.05))) %>%
filter(X2 <= worst_5) %>%
select(X2) %>%
mutate(cvar.2 = mean(X2)) %>%
slice(1)
cvar.xy = data %>%
mutate(X1_X2 = X1+X2) %>%
mutate(worst_5 = as.numeric(quantile(X1_X2, 0.05))) %>%
filter(X1_X2 <= worst_5) %>%
select(X1_X2) %>%
mutate(cvar.comb = mean(X1_X2)) %>%
slice(1)
cvar.xy$cvar.comb-cvar.x$cvar.1-cvar.y$cvar.2
library(MASS)
library(PerformanceAnalytics)
0.7^2
library(MASS)
library(PerformanceAnalytics)
library(dplyr)
sigma = matrix(c(1, 0.7, 0.7, 1), ncol = 2, nrow = 2)
data = data.frame(mvrnorm(n = 1000000, mu = c(0,0), Sigma = sigma))
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05))) %>%
filter(X1 <= worst_5) %>%
select(X1) %>%
mutate(cvar.1 = mean(X1)) %>%
slice(1)
cvar.y = data %>%
select(X2) %>%
arrange(X2) %>%
mutate(worst_5 = as.numeric(quantile(X2, 0.05))) %>%
filter(X2 <= worst_5) %>%
select(X2) %>%
mutate(cvar.2 = mean(X2)) %>%
slice(1)
cvar.xy = data %>%
mutate(X1_X2 = X1+X2) %>%
mutate(worst_5 = as.numeric(quantile(X1_X2, 0.05))) %>%
filter(X1_X2 <= worst_5) %>%
select(X1_X2) %>%
mutate(cvar.comb = mean(X1_X2)) %>%
slice(1)
cor(data[,1], data[,2])
cvar.xy$cvar.comb-cvar.x$cvar.1-cvar.y$cvar.2
data.sum = rnorm(n = 1000000, mu = 0, sigma = sqrt(2+2*0.7))
?rnorm
data.sum = rnorm(n = 1000000, mu = 0, sd = sqrt(2+2*0.7))
data.sum = rnorm(n = 1000000, mean = 0, sd = sqrt(2+2*0.7))
data.sum = data.frame(rnorm(n = 1000000, mean = 0, sd = sqrt(2+2*0.7)))
View(data.sum)
colnames(data.sum)
cvar.xy = data.sum %>%
rename("var" = "rnorm.n...1e.06..mean...0..sd...sqrt.2...2...0.7..") %>%
mutate(worst_5 = as.numeric(quantile(var, 0.05))) %>%
filter(var <= worst_5) %>%
select(var) %>%
mutate(cvar.comb = mean(var)) %>%
slice(1)
View(cvar.xy)
cor(data[,1], data[,2])
cvar.xy$cvar.comb-cvar.x$cvar.1-cvar.y$cvar.2
sigma = matrix(c(1, 0.7, 0.7, 1), ncol = 2, nrow = 2)
data = data.frame(mvrnorm(n = 1000000, mu = c(0,0), Sigma = sigma))
data.sum = data.frame(rnorm(n = 1000000, mean = 0, sd = sqrt(2+2*0.7)))
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05))) %>%
filter(X1 <= worst_5) %>%
select(X1) %>%
mutate(cvar.1 = mean(X1)) %>%
slice(1)
cvar.y = data %>%
select(X2) %>%
arrange(X2) %>%
mutate(worst_5 = as.numeric(quantile(X2, 0.05))) %>%
filter(X2 <= worst_5) %>%
select(X2) %>%
mutate(cvar.2 = mean(X2)) %>%
slice(1)
cvar.xy = data.sum %>%
rename("var" = "rnorm.n...1e.06..mean...0..sd...sqrt.2...2...0.7..") %>%
mutate(worst_5 = as.numeric(quantile(var, 0.05))) %>%
filter(var <= worst_5) %>%
select(var) %>%
mutate(cvar.comb = mean(var)) %>%
slice(1)
?mvnorm
?mvrnorm
cor(data[,1], data[,2])
data.sum = data.frame(rnorm(n = 1000000, mean = 0, sd = 2+2*0.7))
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05))) %>%
filter(X1 <= worst_5) %>%
select(X1) %>%
mutate(cvar.1 = mean(X1)) %>%
slice(1)
cvar.y = data %>%
select(X2) %>%
arrange(X2) %>%
mutate(worst_5 = as.numeric(quantile(X2, 0.05))) %>%
filter(X2 <= worst_5) %>%
select(X2) %>%
mutate(cvar.2 = mean(X2)) %>%
slice(1)
cvar.xy = data.sum %>%
rename("var" = "rnorm.n...1e.06..mean...0..sd...sqrt.2...2...0.7..") %>%
mutate(worst_5 = as.numeric(quantile(var, 0.05))) %>%
filter(var <= worst_5) %>%
select(var) %>%
mutate(cvar.comb = mean(var)) %>%
slice(1)
cor(data[,1], data[,2])
cvar.xy$cvar.comb-cvar.x$cvar.1-cvar.y$cvar.2
library(MASS)
library(PerformanceAnalytics)
library(dplyr)
sigma = matrix(c(1, 0.7, 0.7, 1), ncol = 2, nrow = 2)
data = data.frame(mvrnorm(n = 10000000, mu = c(0,0), Sigma = sigma))
data.sum = data.frame(rnorm(n = 10000000, mean = 0, sd = 2+2*0.7))
cvar.x = data %>%
select(X1) %>%
arrange(X1) %>%
mutate(worst_5 = as.numeric(quantile(X1, 0.05))) %>%
filter(X1 <= worst_5) %>%
select(X1) %>%
mutate(cvar.1 = mean(X1)) %>%
slice(1)
cvar.y = data %>%
select(X2) %>%
arrange(X2) %>%
mutate(worst_5 = as.numeric(quantile(X2, 0.05))) %>%
filter(X2 <= worst_5) %>%
select(X2) %>%
mutate(cvar.2 = mean(X2)) %>%
slice(1)
cvar.xy = data.sum %>%
rename("var" = "rnorm.n...1e.06..mean...0..sd...sqrt.2...2...0.7..") %>%
mutate(worst_5 = as.numeric(quantile(var, 0.05))) %>%
filter(var <= worst_5) %>%
select(var) %>%
mutate(cvar.comb = mean(var)) %>%
slice(1)
View(data.sum)
cvar.xy = data.sum %>%
rename("var" = "rnorm.n...1e.06..mean...0..sd...sqrt.2...2...0.7.") %>%
mutate(worst_5 = as.numeric(quantile(var, 0.05))) %>%
filter(var <= worst_5) %>%
select(var) %>%
mutate(cvar.comb = mean(var)) %>%
slice(1)
colnames(data.sum)
cvar.xy = data.sum %>%
rename("var" = "rnorm.n...1e.07..mean...0..sd...2...2...0.7.") %>%
mutate(worst_5 = as.numeric(quantile(var, 0.05))) %>%
filter(var <= worst_5) %>%
select(var) %>%
mutate(cvar.comb = mean(var)) %>%
slice(1)
cor(data[,1], data[,2])
cvar.xy$cvar.comb-cvar.x$cvar.1-cvar.y$cvar.2
cvar.xy$cvar.comb-cvar.x$cvar.1-cvar.y$cvar.2
simulate.corr.full = function(shift, sigma.1, sigma.0,
n.obs, mu.1, mu.0, alpha){
# shift: upper limit of uniform r.v. (controls mean shifts)
# sigma.1: upper limit of std of Y_1
# sigma.0: upper limit of std of Y_0
# n.obs: number of observations
# mu.1: mean Y_1
# mu.0: mean Y_0
# alpha: alpha of CVaR
set.seed(42)
x = seq(1,10000,1)
n.sample = n.obs
corr = seq(-1, 1, l = 20)
alpha = 0.05
results.corr = matrix(data = NA, nrow = length(corr), ncol = 4)
v = 1
for (c in corr){
tau.vec = numeric()
cdte.mat = matrix(data = NA, nrow = length(x), ncol = 3)
i = 1
for (k in 1:length(x)){
shift.1 = runif(n = 1, 0, shift)
shift.0 = runif(n = 1, 0, shift)
y.1 = rnorm(n = n.sample, mean = mu.1 + shift.1, sd = sigma.1)
y.0 = rnorm(n = n.sample, mean = mu.0 + shift.0, sd = sigma.0)
delta = rnorm(n = n.sample, mean = mu.1+shift.1-(mu.0+shift.0),
sd = sqrt(sigma.1^2+sigma.0^2-2*c*sigma.1*sigma.0))
tau.vec[k] = mean(y.1)-mean(y.0)
cdte.mat[i,1] = max(ES(y.1, p_loss = alpha)-ES(y.0, p_loss = alpha),
ES(-1*y.0, p_loss = alpha)-ES(-1*y.1, p_loss = alpha))
cdte.mat[i,2] = ES(delta, p_loss = alpha)
cdte.mat[i,3] = ES(y.1, p_loss = alpha) + ES(-1*y.0, p_loss = alpha)
i = i + 1
}
cvar.kall = ES(tau.vec, p_loss = alpha)
cvar.us = colMeans(cdte.mat)
results.corr[v,1] = cvar.us[1]
results.corr[v,2] = cvar.us[2]
results.corr[v,3] = cvar.us[3]
results.corr[v,4] = cvar.kall
v = v + 1
}
corr.df = data.frame(results.corr) %>%
rename("LB" = "X1",
"True" = "X2",
"UB" = "X3",
"Kallus" = "X4") %>%
mutate(corr = corr) %>%
pivot_longer(cols = c("LB", "True", "UB", "Kallus")) %>%
arrange(name, corr)
return(corr.df)
}
rm(list = ls())
library(dplyr)
library(tidyr)
library(cvar)
library(ggplot2)
library(ggsci)
library(gganimate)
setwd("C:/Users/eminu/OneDrive/Desktop/Treatment-Effect-Risk")
source("./Simulation/helperfunctions.R")
simulate.full.data = function(shift, sigma.1, sigma.0,
n.obs, mu.1, mu.0, alpha){
# shift: upper limit of uniform r.v. (controls mean shifts)
# sigma.1: upper limit of std of Y_1
# sigma.0: upper limit of std of Y_0
# n.obs: number of observations
# mu.1: mean Y_1
# mu.0: mean Y_0
# alpha: alpha of CVaR
set.seed(42)
max.var = sigma.1^2+sigma.0^2+2*sigma.1*sigma.0
x = seq(1,10000,1)
corr = seq(-1, 1, l = 20)
sd = list(seq(0, sigma.1, l = 20), seq(0, sigma.0, l = 20))
alpha = 0.05
results.sigma.shift = matrix(data = NA, nrow = length(sd[[1]])*length(corr), ncol = 7)
v = 1
for (c in corr){
for(k in 1:length(sd[[1]])){
tau.vec = numeric()
cdte.mat = matrix(data = NA, nrow = length(x), ncol = 3)
i = 1
for (j in 1:length(x)){
shift.1 = runif(n = 1, 0, shift)
shift.0 = runif(n = 1, 0, shift)
y.1 = rnorm(n = n.obs, mean = mu.1+shift.1, sd = sd[[1]][k])
y.0 = rnorm(n = n.obs, mean = mu.0+shift.0, sd = sd[[2]][k])
delta = rnorm(n = n.obs, mean = mu.1+shift.1-(mu.0+shift.0),
sd = sqrt(sd[[1]][k]^2+sd[[2]][k]^2-2*c*sd[[1]][k]*sd[[2]][k]))
tau.vec[j] = mean(y.1)-mean(y.0)
cdte.mat[i,1] = max(ES(y.1, p_loss = alpha)-ES(y.0, p_loss = alpha),
ES(-1*y.0, p_loss = alpha)-ES(-1*y.1, p_loss = alpha))
cdte.mat[i,2] = ES(delta, p_loss = alpha)
cdte.mat[i,3] = ES(y.1, p_loss = alpha) + ES(-1*y.0, p_loss = alpha)
i = i + 1
}
cvar.kall = ES(tau.vec, p_loss = alpha)
cvar.us = colMeans(cdte.mat)
results.sigma.shift[v,1] = cvar.us[1]
results.sigma.shift[v,2] = cvar.us[2]
results.sigma.shift[v,3] = cvar.us[3]
results.sigma.shift[v,4] = cvar.kall
results.sigma.shift[v,5] = c
results.sigma.shift[v,6] = sd[[1]][k]
results.sigma.shift[v,7] = sd[[2]][k]
v = v + 1
}
}
sigma.shift.df = data.frame(results.sigma.shift) %>%
rename("LB" = "X1",
"True" = "X2",
"UB" = "X3",
"Kallus" = "X4",
"Corr" = "X5",
"Se.1" = "X6",
"Se.0" = "X7") %>%
mutate(var.delta.x = Se.1^2+Se.0^2-2*Corr*Se.1*Se.0,
var.delta.x.group = cut(var.delta.x, breaks = 30,
include.lowest = T),
var.delta.x.group = round((as.numeric(var.delta.x.group)-1)*max.var/30, 1),
var.delta.x.group = factor(var.delta.x.group)) %>%
group_by(var.delta.x.group) %>%
summarise(LB = mean(LB),
True = mean(True),
UB = mean(UB),
Kallus = mean(Kallus)) %>%
pivot_longer(cols = c("LB", "True", "UB", "Kallus")) %>%
arrange(name, value)
return(sigma.shift.df)
}
# Now compare our results with Kallus depending on Var(delta\mid X)
data.comp = simulate.full.data(shift = 2, sigma.1 = 2, sigma.0 = 2, n.obs = 10000, mu.1 = 1, mu.0 = 1, alpha = 0.05)
